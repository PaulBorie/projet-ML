{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, MaxPooling2D,Dropout\n",
    "import freeman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On load le dataset MNIST qui comporte 70000 images au format 28*28 pixels.\n",
    "On divise le dataset avec 85 % des images pour les données d'entrainements et 15 pourcent des images pour les données de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**on convertit les images en matrices de piexl de 0 et 1**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train = freeman.convert_binary(x_train)\n",
    "X_test = freeman.convert_binary(x_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On ajoute une dimension qui ne change pas les données pour pouvoir utiliser les données avec Tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train into one-hot format \n",
    "temp = []\n",
    "for i in range(len(y_train)):\n",
    "    temp.append(to_categorical(y_train[i], num_classes=10))\n",
    "\n",
    "y_train = np.array(temp)\n",
    "\n",
    "# Convert y_test into one-hot format \n",
    "temp = []\n",
    "for i in range(len(y_test)):\n",
    "    temp.append(to_categorical(y_test[i], num_classes=10))\n",
    "\n",
    "y_test = np.array(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Définition du modèle choisi pour le réseau :**\n",
    "\n",
    "**-on créer deux couches successives de Convolution/Sampling avec du max pooling pour tenter de reconnaitre les patterns propre a la reconnaissance de chiffre.**\n",
    "\n",
    "**-On va ensuite réduire en un vecteur d'une dimension les sorties résultantes du second max pooling avec la couche \"flatten\" pour pouvoir passer toute les entrées à la dernière couche qui n'est autre qu'un classique mlp à 10 sorties.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 68,938\n",
      "Trainable params: 68,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.output_shape\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On entraine le modèle obtenu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.1767 - acc: 0.9452 - val_loss: 0.0666 - val_acc: 0.9787\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0693 - acc: 0.9785 - val_loss: 0.0449 - val_acc: 0.9849\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0541 - acc: 0.9830 - val_loss: 0.0447 - val_acc: 0.9852\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0439 - acc: 0.9857 - val_loss: 0.0347 - val_acc: 0.9882\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0373 - acc: 0.9881 - val_loss: 0.0455 - val_acc: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd58e9d5cc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test,y_test))\n",
    "# On enregistre le modèle entrainé dans un fichier pour pouvoir le réutiliser dans l'interface graphique\n",
    "model.save(\"digit_recognition_binary.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On test le modèle sur l'ensemble de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using our trained model\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On affiche 10 prédictions sur les images de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# On affiche 10 prédictions sur les images de test\n",
    "fig, axes = plt.subplots(ncols=10, sharex=False,\n",
    "\t\t\t sharey=True, figsize=(20, 4))\n",
    "for i in range(10):\n",
    "\taxes[i].set_title(predictions[i])\n",
    "\taxes[i].imshow(X_test[i], cmap='gray')\n",
    "\taxes[i].get_xaxis().set_visible(False)\n",
    "\taxes[i].get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
